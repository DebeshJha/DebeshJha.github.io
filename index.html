<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Debesh Jha</title>
  <link rel="stylesheet" href="css/styles.css">
</head>
<body>

  <header>
    <h1>Debesh Jha, PhD</h1>
    <p>Assistant Professor (Tenure-Track), Department of Computer Science, University of South Dakota | IEEE Senior Member| Top 2% Scientist in AI & Biomedical Engineering (Stanford‚ÄìElsevier Ranking)</p>
  </header>

  <section class="profile">
  <img src="images/debesh-profile.jpg" alt="Debesh Jha" class="profile-img" />
</section>


<nav>
    <ul>
      <li><a href="index.html">Home</a></li>
      <li><a href="pages/publications.html">Publication</a></li>
      <li><a href="pages/datasets.html">Dataset</a></li>
      <li><a href="pages/codes.html">Codes</a></li>
      <li><a href="pages/invitedtalks.html">Invited Talks</a></li>
      <li><a href="pages/links.html">Useful Links</a></li>
      <li><a href="pages/workshop.html">Workshop and Competition</a></li>
      <li><a href="pages/supervision.html">Supervision</a></li>
      <li><a href="pages/service.html">Services</a></li>
      <li><a href="pages/service.html">Contact</a></li>
      <li><a href="pages/blog.html">Blogs</a></li>
    </ul>
  </nav>



  <section id="about">
    <h2>About Me</h2>
    <p>I develop human-centered, trustworthy AI systems that learn to see, interpret, and reason like clinicians, with the goal of making expert-level diagnosis faster, fairer, and universally accessible. As an Assistant Professor of Computer Science at the University of South Dakota and Senior AI Scientist at Ther-AI LLC, I lead pioneering research at the intersection of computer vision, biomedical informatics, and clinical practice. My work spans multimodal AI integration, large-scale medical dataset curation, and the development of energy-efficient models deployable on low-end devices‚Äîpushing the boundaries of real-world impact in healthcare.

      My journey began with a deep commitment to solving medical problems through algorithmic intelligence. Trained in computer science and biomedical engineering, I have led innovations across gastrointestinal imaging (esophagus, IBD, ERCP, colonoscopy, and video capsule endoscopy), thoracic and abdominal radiology (liver, lung, pancreas, prostate), and radiation therapy planning. To overcome the longstanding bottleneck of data scarcity in endoscopy, I spearheaded the creation of some of the world‚Äôs largest and most-used public datasets‚ÄîHyperKvasir, KvasirCapsule, and PolypDB‚Äînow cited and benchmarked globally.

      My segmentation models, including ColonSegNet, ResUNet++, and DoubleUNet, are widely adopted in academia and industry. ColonSegNet has been integrated into NVIDIA Clara Holoscan, a milestone demonstrating the clinical scalability of my work. As a PI, I lead multi-institutional collaborations and NIH/NSF-aligned initiatives aimed at building explainable AI tools that radiologists can trust‚Äîblending transformers, Mamba architectures, language-vision models, and human-in-the-loop AI into high-performance diagnostic systems.

      With over 125 peer-reviewed publications and 7,800+ citations, my research has shaped the global discourse on AI for medical imaging. Recognized as a Top 2% Scientist Worldwide (Stanford/Elsevier), I‚Äôve received multiple honors including the Meta Paper with Code Award, IEEE Distinguished R&D Award, and Best Paper Awards at IEEE and IAPR. I actively mentor students, lead open science efforts, and organize international medical AI workshops to democratize innovation.

      Driven by a vision of equitable, AI-augmented healthcare, I continue to design technologies that not only diagnose but also empower clinicians, reduce the burden, and save lives.

</p>
  </section>

  <section id="news">
    <h2>Recent News</h2>
    <ul>
      <li>2 papers are accepted at the 2024 CVPR Workshop.</li>
      <li>Acting as an associate editor for Frontiers in Radiation Oncology and Medical Physics Journal.</li>
      <li>One paper was accepted at the ICML workshop in 2023.</li>
      <li>Our Kvasir-SEG dataset was mentioned in the ‚ÄúArtificial Intelligence Index Report 2022‚Äù from Stanford University.</li>
    </ul>
  </section>

  <section id="links">
    <h2>Useful Links</h2>
    <ul>
      <li><a href="https://scholar.google.com/citations?user=mMTyE68AAAAJ&hl=en">Google Scholar</a></li>
      <li><a href="https://www.researchgate.net/profile/Debesh-Jha?ev=hdr_xprf">ResearchGate</a></li>
      <li><a href="https://github.com/DebeshJha">GitHub</a></li>
      <li><a href="https://www.linkedin.com/in/debesh-jha-ph-d-071462aa/">LinkedIn</a></li>
      <li><a href="https://x.com/debesh_jha">X</a></li>
      <li><a href="https://www.semanticscholar.org/author/Debesh-Jha/34665941">Semantic Scholar</a></li>
      <li><a href="https://dblp.org/pid/211/9569.html">dblp</a></li>
      <li><a href="https://orcid.org/0000-0002-8078-6730">ORCiD</a></li>
    </ul>
  </section>



<section id="mission">
  <h2>Mission</h2>
  <p style="font-size: 1.1em;"><strong>At the heart of our lab is a singular mission:</strong><br>
  To build intelligent systems that can see, reason, and learn like clinicians‚Äîadvancing medicine for every patient, everywhere. We believe that the next breakthroughs in healthcare will come not from replacing doctors, but from empowering them with AI that is transparent, trustworthy, and human-centered. 
    Our work sits at the cutting edge of deep learning, computer vision, language modeling, and multimodal intelligence, with a relentless focus on solving real-world problems in medical imaging, diagnostics, and decision support.
    From GI endoscopy and oncology to radiology and radiation therapy, we are building the tools that redefine what‚Äôs possible in clinical AI.
  </p>

  <h3 style="margin-top: 20px;">We stand for:</h3>
  <ul>
    <li>‚úÖ <strong>Scientific rigor</strong> over hype</li>
    <li>üåç <strong>Open science</strong> over silos</li>
    <li>ü§ù <strong>Global accessibility</strong> over exclusivity</li>
    <li>üõ°Ô∏è <strong>Responsible AI</strong> that earns trust through transparency, robustness, and equity</li>
  </ul>

  <p style="margin-top: 20px; font-style: italic;">
    The future of healthcare is intelligent.<br>
    <strong>We‚Äôre building it‚Äîone dataset, one model, and one breakthrough at a time.</strong>
  </p>
</section>


<section id="research">
  <h2>Core Research Areas</h2>
  <ul>
    <li><strong>üß† Gastrointestinal AI:</strong> Advanced solutions for IBD, ERCP, and colonoscopy imaging.<br />
      Creator of <em>HyperKvasir, KvasirCapsule, PolypDB</em>; algorithms for polyp detection, VCE classification, automated reporting.</li><br />

    <li><strong>ü©ª Radiological Imaging:</strong> Deep learning-based segmentation of liver, spleen, pancreas, lung, prostate, and retina (CT/MRI).<br />
      Includes organ-at-risk delineation and radiation therapy dose prediction.</li><br />

    <li><strong>üß¨ Multimodal & Foundational AI:</strong> Vision-language and reasoning models integrating imaging with clinical texts.<br />
      Language-guided diagnostics and explainable, automated decision-making.</li><br />

    <li><strong>‚öôÔ∏è Efficient & Ethical AI:</strong> Lightweight real-time models (e.g., ColonSegNet in NVIDIA Clara).<br />
      Green AI, federated learning, semi-supervised learning, ethical and human-in-the-loop systems.</li><br />

    <li><strong>üéØ Applied AI in Diverse Domains:</strong> Surgical tool tracking, Alzheimer‚Äôs classification, retina/skin lesion segmentation, sports biomechanics, and remote patient monitoring.</li>
  </ul>
</section>

<section id="impact">
  <h2>Academic & Industry Impact</h2>
  <ul>
    <li>üìù Authored <strong>125+</strong> peer-reviewed publications (MedIA, IEEE TMI, J-BHI, MICCAI, ISBI, CVPR Workshops)</li>
    <li>üìä <strong>7,850+ citations</strong>, h-index: <strong>32</strong>, i10-index: <strong>49</strong></li>
    <li>üõ†Ô∏è Creator of models: <em>ResUNet++, DoubleUNet, ColonSegNet, MSRF-Net, FANet, TGANet, PNS-Net, DDANet</em></li>
    <li>üåç Developed benchmark datasets used globally for segmentation/classification tasks</li>
  </ul>
</section>

<section id="recognitions">
  <h2>Recognitions & Leadership</h2>
  <ul>
    <li>üèÜ Best Paper/Poster Awards at IEEE ICEIC (2018), IAPR (2024), IEEE CBMS (Finalist)</li>
    <li>üèÖ IEEE Chicago Distinguished R&D Award (2025), Meta's Paper with Code Contributor Award</li>
    <li>‚≠ê IEEE TMI Distinguished Reviewer (2023‚Äì2024)</li>
    <li>üõÇ EB1A Green Card Holder (Extraordinary Ability)</li>
    <li>üìö Guest Editor: Medical Physics, Frontiers in Oncology, Diagnostics</li>
    <li>üß™ Organizer of FAIMI-EPIMI (MICCAI), MedAI Challenge, Kvasir Dataset Series</li>
  </ul>
</section>

    <section id="awards">
  </section>


  <section id="interests">
    <h2>Research Interests</h2>
    <p>Medical image analysis, Medical image segmentation, Deep learning, Radiation therapy, Dose Prediction, Gastrointestinal endoscopy & wireless capsule endoscopy, Polyp segmentation, detection, and localization, Surgical data science, Prostate and lung cancer segmentation, Robust and trustworthy AI systems, Ethical AI, Sport Analytics</p>
  </section>

  <section id="contact">
    <h2>Contact</h2>
    <p>Email: <a href="mailto:debeshjha1@gmail.com">debeshjha@gmail.com</a></p>
  </section>

  <footer>
    <p>&copy; 2025 Debesh Jha. All rights reserved.</p>
  </footer>

</body>
</html>
